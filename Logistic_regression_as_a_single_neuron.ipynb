{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d3c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from test_cases import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ba6028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logitic Loss\n",
    "def compute_cost(w, b, X, Y):\n",
    "    m = Y.shape[1]\n",
    "    A, cache = sigmoid(np.dot(w.T, X) + b)\n",
    "    cost = (1/m)*np.sum((-Y*np.log(A)-(1-Y)*np.log(1-A)))\n",
    "    cost = np.squeeze(cost)\n",
    "    dw = (1/m) * np.dot(X, (A-Y).T)\n",
    "    db = (1/m) * np.sum(A-Y)\n",
    "    assert(dw.shape == w.shape)\n",
    "    grads = {\"dw\":dw,\n",
    "            \"db\":db}\n",
    "    return grads, cost\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74ad6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing compute cost\n",
    "X = np.random.rand(3,4)\n",
    "w = np.random.rand(3,1)\n",
    "b = 0\n",
    "Y = np.random.rand(1,4)\n",
    "# print(X)\n",
    "grads, cost =compute_cost(w, b, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "de8f2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "def optimisation(w, b, X, Y, learning_rate=0.001, num_iterations=2000, print_cost = True):\n",
    "    \n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = compute_cost(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w-learning_rate*dw\n",
    "        b = b-learning_rate*db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"cost after iteration %i: %f\", (i, cost))\n",
    "            \n",
    "    params = {\"w\":w,\n",
    "             \"b\":b}\n",
    "    grads = {\"dw\":dw,\n",
    "            \"db\":db}\n",
    "    return params, grads, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "63da5d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after iteration %i: %f (0, 0.8439989047058736)\n",
      "cost after iteration %i: %f (100, 0.8321765191233164)\n",
      "cost after iteration %i: %f (200, 0.8210771502783949)\n",
      "cost after iteration %i: %f (300, 0.8106638869361078)\n",
      "cost after iteration %i: %f (400, 0.8009005964285678)\n",
      "cost after iteration %i: %f (500, 0.7917520767289005)\n",
      "cost after iteration %i: %f (600, 0.7831841812425229)\n",
      "cost after iteration %i: %f (700, 0.7751639180988896)\n",
      "cost after iteration %i: %f (800, 0.7676595259931118)\n",
      "cost after iteration %i: %f (900, 0.7606405287872762)\n",
      "cost after iteration %i: %f (1000, 0.7540777711515924)\n",
      "cost after iteration %i: %f (1100, 0.7479434375217916)\n",
      "cost after iteration %i: %f (1200, 0.7422110565870812)\n",
      "cost after iteration %i: %f (1300, 0.7368554934167777)\n",
      "cost after iteration %i: %f (1400, 0.7318529311962905)\n",
      "cost after iteration %i: %f (1500, 0.7271808443853948)\n",
      "cost after iteration %i: %f (1600, 0.7228179649428397)\n",
      "cost after iteration %i: %f (1700, 0.7187442430886746)\n",
      "cost after iteration %i: %f (1800, 0.714940803904959)\n",
      "cost after iteration %i: %f (1900, 0.7113899009110426)\n"
     ]
    }
   ],
   "source": [
    "# Test Optimizer\n",
    "X = np.random.rand(3,4)\n",
    "w = np.random.rand(3,1)\n",
    "b = 0\n",
    "Y = np.random.rand(1,4)\n",
    "# print(X)\n",
    "params, grads, cost = optimisation(w, b, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aa9acb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def predict(w, b, X, threshold = 0.5):\n",
    "    m = X.shape[1]\n",
    "    y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    A, cache = sigmoid(np.dot(w.T, X)+b)\n",
    "    A = A.reshape(-1,1)\n",
    "    for i in range(A.shape[0]):\n",
    "        y_prediction[0:i] = 1 if A[i] > threshold else 0\n",
    "    assert(y_prediction.shape == (1,m))\n",
    "    return y_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "616d93e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test predict\n",
    "predicted = predict(w, b, X)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8c26c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_with_zeros(dim):\n",
    "    w = np.zeros(shape=(dim, 1))\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dd8ae3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.001, print_cost=True):\n",
    "    w, b = initialise_with_zeros(X_train.shape[0])\n",
    "    \n",
    "    parameters, gradients, cost = optimisation(w, b, X, Y, learning_rate, num_iterations, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    y_prediction_train = predict(w, b, X_train)\n",
    "    y_prediction_test = predict(w, b, X_test)\n",
    "    \n",
    "    \n",
    "    print(\"train accuracy: {}%\".format(100 - np.mean(np.abs(y_prediction_train - Y_train))*100))\n",
    "    print(\"test accuracy: {}%\".format(100 - np.mean(np.abs(y_prediction_test - Y_test))*100))\n",
    "    \n",
    "    d = {\"cost\": cost,\n",
    "        \"Y_pred_test\": y_prediction_test,\n",
    "        \"Y_pred_train\": y_prediction_train,\n",
    "        \"w\" : w,\n",
    "        \"b\" : b,\n",
    "        \"Learning_rate\" : learning_rate,\n",
    "        \"num_iterations\" : num_iterations}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8a914730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# costs = np.squeeze(d['costs'])\n",
    "# plt.plot(costs)\n",
    "# plt.ylabel('cost')\n",
    "# plt.xlabel('iterations (per hundreds)')\n",
    "# plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ff4009ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after iteration %i: %f (0, 0.6931471805599453)\n",
      "cost after iteration %i: %f (100, 0.6903781225110525)\n",
      "cost after iteration %i: %f (200, 0.6877953788781503)\n",
      "cost after iteration %i: %f (300, 0.6853863362354586)\n",
      "cost after iteration %i: %f (400, 0.6831392124815323)\n",
      "cost after iteration %i: %f (500, 0.6810430079041361)\n",
      "cost after iteration %i: %f (600, 0.6790874580174175)\n",
      "cost after iteration %i: %f (700, 0.6772629883160441)\n",
      "cost after iteration %i: %f (800, 0.6755606710416814)\n",
      "cost after iteration %i: %f (900, 0.67397218401628)\n",
      "cost after iteration %i: %f (1000, 0.6724897715630457)\n",
      "cost after iteration %i: %f (1100, 0.6711062075087436)\n",
      "cost after iteration %i: %f (1200, 0.669814760239249)\n",
      "cost after iteration %i: %f (1300, 0.6686091597631836)\n",
      "cost after iteration %i: %f (1400, 0.6674835667253914)\n",
      "cost after iteration %i: %f (1500, 0.6664325433022475)\n",
      "cost after iteration %i: %f (1600, 0.6654510259038242)\n",
      "cost after iteration %i: %f (1700, 0.6645342996032768)\n",
      "cost after iteration %i: %f (1800, 0.6636779742110432)\n",
      "cost after iteration %i: %f (1900, 0.6628779619102048)\n",
      "train accuracy: 30.669449127902453%\n",
      "test accuracy: 37.33528428941756%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cost': 0.662137683362138,\n",
       " 'Y_pred_test': array([[0., 0., 0., 0.]]),\n",
       " 'Y_pred_train': array([[0., 0., 0., 0.]]),\n",
       " 'w': array([[-0.10473536],\n",
       "        [-0.05328823],\n",
       "        [-0.08415308]]),\n",
       " 'b': -0.19695498847205398,\n",
       " 'Learning_rate': 0.001,\n",
       " 'num_iterations': 2000}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model test\n",
    "X_train = np.random.rand(3,4)\n",
    "X_test = np.random.rand(3,4)\n",
    "Y_train = np.random.rand(1,4)\n",
    "Y_test = np.random.rand(1,4)\n",
    "d = model(X_train, Y_train, X_test, Y_test)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b931bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Learning rate0.1\n",
      "train accuracy: 56.818868342818746%\n",
      "test accuracy: 70.48613482174046%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24404/1240826665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m  \u001b[1;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Using Learning rate\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"-------------------------------------------------------\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i  in learning_rates:\n",
    "    print(\"Using Learning rate\" + str(i))\n",
    "    model[str(i): model(X_train, Y_train, X_test, Y_test, num_iterations = 1500, learning_rate = i, print_cost = False)]\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "    \n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label = str(model[str(i)][\"learning_rate\"]))\n",
    "    \n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('learning_rate')\n",
    "    \n",
    "    legend = plt.legend(loc='upper center', shadow=True)\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_image = \"my_image.jpg\"   # change this to the name of your image file \n",
    "# ## END CODE HERE ##\n",
    "\n",
    "# # We preprocess the image to fit your algorithm.\n",
    "# fname = \"images/\" + my_image\n",
    "# image = np.array(ndimage.imread(fname, flatten=False))\n",
    "# my_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((1, num_px * num_px * 3)).T\n",
    "# my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "# plt.imshow(image)\n",
    "# print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
